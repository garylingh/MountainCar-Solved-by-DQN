# Mountcar-Solved-by-DQN

The "Reward" from Original OpenAI GYM MountCar-v0 "Environment" is useless.  You can Not learn from it.  To let then the Agent learns and builds the Q-table, we must re-define and create a new reward system.

By MountainCart-v0 definitions:
## Obervation
Num | Observation | Min | Max
--:|:--|--:|--:
0| Car Position | -1.2 | 0.6
1| Car Velocity | -007 | 0.07
